{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules & Set Environment Variables:\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import types as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/23 18:21:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession:\n",
    "# A new SparkSession is created with the name 'ex5_google_reviews', using a single local node.\n",
    "spark = SparkSession.builder.master(\"local\").appName('ex5_google_reviews').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Sentiment='Positive', sentiment_rank=1), Row(Sentiment='Neutral', sentiment_rank=0), Row(Sentiment='Negative', sentiment_rank=-1)]\n"
     ]
    }
   ],
   "source": [
    "# Setting Up Sentiment Mapping:\n",
    "# This sets up an array of Row objects to map the sentiment to respective ranks.\n",
    "sentiment_arr = [Row(Sentiment='Positive', sentiment_rank=1),\n",
    "Row(Sentiment='Neutral', sentiment_rank=0),\n",
    "Row(Sentiment='Negative', sentiment_rank=-1)]\n",
    "print(sentiment_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------------------+----------------------+\n",
      "|                 App|   Translated_Review|           Sentiment|Sentiment_Polarity|Sentiment_Subjectivity|\n",
      "+--------------------+--------------------+--------------------+------------------+----------------------+\n",
      "|10 Best Foods for...|\"I like eat delic...| also \"\"Best Befo...|          Positive|                   1.0|\n",
      "|10 Best Foods for...|This help eating ...|            Positive|              0.25|   0.28846153846153844|\n",
      "|10 Best Foods for...|                 nan|                 nan|               nan|                   nan|\n",
      "|10 Best Foods for...|Works great espec...|            Positive|               0.4|                 0.875|\n",
      "|10 Best Foods for...|        Best idea us|            Positive|               1.0|                   0.3|\n",
      "|10 Best Foods for...|            Best way|            Positive|               1.0|                   0.3|\n",
      "+--------------------+--------------------+--------------------+------------------+----------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Loading\n",
    "# Load the Google Reviews CSV data into a DataFrame.\n",
    "google_reviews_df = spark.read.csv('s3a://spark/data/raw/google_reviews/', header=True)\n",
    "google_reviews_df.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code solution\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import types as T\n",
    "spark = SparkSession.builder.master(\"local\").appName('ex5_google_reviews').getOrCreate()\n",
    "sentiment_arr = [Row(Sentiment='Positive', sentiment_rank=1),\n",
    "Row(Sentiment='Neutral', sentiment_rank=0),\n",
    "Row(Sentiment='Negative', sentiment_rank=-1)]\n",
    "print(sentiment_arr)\n",
    "google_reviews_df = spark.read.csv('s3a://spark/data/raw/google_reviews/', header=True)\n",
    "google_reviews_df.show(6)\n",
    "sentiments_df = spark.createDataFrame(sentiment_arr)\n",
    "sentiments_df.show()\n",
    "joined_df = google_reviews_df.join(F.broadcast(sentiments_df), ['Sentiment'])\n",
    "selected_df = joined_df \\\n",
    ".select(F.col('App').alias('application_name'),\n",
    "F.col('Translated_Review').alias('translated_review'),\n",
    "F.col('sentiment_rank'),\n",
    "F.col('Sentiment_Polarity').cast(T.FloatType()).alias('sentiment_polarity'),\n",
    "F.col('Sentiment_Subjectivity').cast(T.FloatType()).alias('sentiment_subjectivity'))\n",
    "selected_df.show()\n",
    "selected_df.printSchema()\n",
    "selected_df.write.parquet('s3a://spark/data/source/google_reviews', mode='overwrite')\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
