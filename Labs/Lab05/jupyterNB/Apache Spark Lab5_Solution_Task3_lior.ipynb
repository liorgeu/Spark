{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import Required Modules & Set Environment Variables\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/24 08:10:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession:\n",
    "# This creates a new SparkSession with the name 'ex5_reviews_producer', running on a single\n",
    "# local node.\n",
    "spark = SparkSession.builder.master(\"local\").appName('ex5_reviews_producer').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/24 08:11:14 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------+------------------+----------------------+\n",
      "|    application_name|   translated_review|sentiment_rank|sentiment_polarity|sentiment_subjectivity|\n",
      "+--------------------+--------------------+--------------+------------------+----------------------+\n",
      "|10 Best Foods for...|This help eating ...|             1|              0.25|            0.28846154|\n",
      "|10 Best Foods for...|Works great espec...|             1|               0.4|                 0.875|\n",
      "|10 Best Foods for...|        Best idea us|             1|               1.0|                   0.3|\n",
      "|10 Best Foods for...|            Best way|             1|               1.0|                   0.3|\n",
      "|10 Best Foods for...|             Amazing|             1|               0.6|                   0.9|\n",
      "|10 Best Foods for...|Looking forward app,|             0|               0.0|                   0.0|\n",
      "+--------------------+--------------------+--------------+------------------+----------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Data:\n",
    "# Load data from Parquet file into a DataFrame .\n",
    "# Here, the processed Google reviews data is loaded from a Parquet file into a DataFrame and\n",
    "# displayed.\n",
    "data_df = spark.read.parquet('s3a://spark/data/source/google_reviews/')\n",
    "data_df.show(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"application_name\":\"10 Best Foods for You\",\"translated_review\":\"This help eating healthy exercise regular basis\",\"sentiment_rank\":1,\"sentiment_polarity\":0.25,\"sentiment_subjectivity\":0.28846154}', '{\"application_name\":\"10 Best Foods for You\",\"translated_review\":\"Works great especially going grocery store\",\"sentiment_rank\":1,\"sentiment_polarity\":0.4,\"sentiment_subjectivity\":0.875}', '{\"application_name\":\"10 Best Foods for You\",\"translated_review\":\"Best idea us\",\"sentiment_rank\":1,\"sentiment_polarity\":1.0,\"sentiment_subjectivity\":0.3}', '{\"application_name\":\"10 Best Foods for You\",\"translated_review\":\"Best way\",\"sentiment_rank\":1,\"sentiment_polarity\":1.0,\"sentiment_subjectivity\":0.3}', '{\"application_name\":\"10 Best Foods for You\",\"translated_review\":\"Amazing\",\"sentiment_rank\":1,\"sentiment_polarity\":0.6,\"sentiment_subjectivity\":0.9}', '{\"application_name\":\"10 Best Foods for You\",\"translated_review\":\"Looking forward app,\",\"sentiment_rank\":0,\"sentiment_polarity\":0.0,\"sentiment_subjectivity\":0.0}']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert Data to JSON:\n",
    "data = data_df.toJSON ()\n",
    "print(data.take(6))\n",
    "\n",
    "#Each record in the DataFrame is converted to a JSON string, which is a suitable format for\n",
    "#sending messages to a Kafka topic. A sample of six JSON records is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Kafka Producer:\n",
    "#Set up a Kafka producer .\n",
    "producer = KafkaProducer(bootstrap_servers='course-kafka:9092', value_serializer=lambda v: v.encode('utf-8'))\n",
    "\n",
    "# A KafkaProducer instance is initialized to send messages to the Kafka cluster. The producer\n",
    "# will serialize the messages (JSON strings) into bytes using UTF-8 encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m50\u001b[39m:\n\u001b[1;32m      8\u001b[0m         producer\u001b[39m.\u001b[39mflush()\n\u001b[0;32m----> 9\u001b[0m         time\u001b[39m.\u001b[39;49msleep(\u001b[39m5\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m         i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39m# In this loop, each JSON string is sent as a message to the gps-user-review-source Kafka topic. After\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# sending 50 messages, the producer buffers are flushed, ensuring that all messages are sent.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Produce Messages to Kafka Topic:\n",
    "i = 0\n",
    "\n",
    "for json_data in data.collect():\n",
    "    i = i + 1\n",
    "    producer.send(topic='gps-user-review-source', value=json_data)\n",
    "    if i == 50:\n",
    "        producer.flush()\n",
    "        time.sleep(5)\n",
    "        i = 0\n",
    "'''\n",
    "In this loop, each JSON string is sent as a message to the gps-user-review-source Kafka topic. After\n",
    "sending 50 messages, the producer buffers are flushed, ensuring that all messages are sent.\n",
    "Then the script waits for 10 seconds before resuming. This pattern is used to space out the\n",
    "message production, sending 50 messages every 10 seconds.\n",
    "'''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Kafka Producer & Terminate SparkSession:\n",
    "producer.close()\n",
    "spark.stop()\n",
    "\n",
    "''' \n",
    "After all messages have been sent, the Kafka producer is closed to release resources,\n",
    "followed by terminating the SparkSession.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summery\n",
    "\n",
    "'''\n",
    "    This solution reads the processed Google Reviews data, converts it to JSON, and then\n",
    "    produces the messages to a Kafka topic in batches of 50, with a 10-second interval between\n",
    "    batches.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
